import json
from os import getenv

from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from langchain_core.output_parsers.string import StrOutputParser

from schemas import ModerationResponse

llm = ChatOllama(
    model="mistral",
    base_url=getenv("OLLAMA_BASE_URL", "http://localhost:11434"),
    temperature=0.0
)

async def check_if_message_is_about_banned_topic(message: str, topics: list[str]) -> ModerationResponse:
    prompt = ChatPromptTemplate.from_messages([
        SystemMessagePromptTemplate.from_template(
            "Tu es un assistant de modÃ©ration **zÃ©ro tolÃ©rance**. "
            "Ta mission est de dÃ©tecter **tout contenu inappropriÃ©**, y compris :\n"
            "  â€¢ insulte directe ou dÃ©guisÃ©e (ex. Â«fdpÂ», Â«salaudÂ», Â«enculÃ©Â»)\n"
            "  â€¢ discours haineux (racisme, sexisme, homophobieâ€¦)\n"
            "  â€¢ apologie de la violence ou de la drogue\n"
            "  â€¢ tout propos violant les rÃ¨gles de civilitÃ©\n\n"
            "Tu dois comprendre **toutes les langues**. Si le message contient **la moindre infraction**, mÃªme implicite:\n"
            "- **retourne** exactement la chaÃ®ne:  \n"
            "  `delete|<raison courte en franÃ§ais>`\n\n"
            "Sinon:\n"
            "- **retourne** exactement:  \n"
            "  `nothing`\n\n"
            "ğŸ”¹ **Exemples**:\n"
            "  â€¢ message = Â«fdpÂ» â†’ `delete|insulte Â«fdpÂ»`\n"
            "  â€¢ message = Â«Bonjour tout le mondeÂ» â†’ `nothing`\n"
        ),
        HumanMessagePromptTemplate.from_template(
            "Message Ã  analyser : {message}\n"
            "Sujets interdits : {topics}\n\n"
            "Le message fait-il rÃ©fÃ©rence Ã  lâ€™un de ces sujets, de maniÃ¨re directe ou indirecte ? "
            "RÃ©ponds uniquement au format JSON comme ceci :\n"
            "{{ \"action\": delete, \"reason\": \"Votre message contient un sujet interdit (le sujet interdit)\" }}"
        ),
    ])

    chain = prompt | llm | StrOutputParser()

    response = await chain.ainvoke({"message": message, "topics": topics})

    try:
        data = json.loads(response)
        return ModerationResponse(**data)
    except Exception:
        return ModerationResponse(action="nothing", reason="RÃ©ponse invalide ou mal formÃ©e")